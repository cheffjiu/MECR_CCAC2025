## MECR_CCAC2025 数据清洗模块开发书

### 1. 概述

本开发模块旨在将原始 `train.json` 样本与视频帧对齐、解析时间戳、按照新的关键帧采样策略截取关键帧并构造标准化输出结构，便于后续数据加载和模型训练。设计采用面向对象方法，遵循 SOLID 原则，并引入常用设计模式（Factory、Builder、Strategy），保证代码可扩展、易维护。

### 2. 输入/输出格式

#### 2.1 输入数据

* **train.json** 中每条样本格式：

```json
"{sample_id}": {
  "video_path": "<relative_path>.mp4",
  "utts": {
    "{utt_id}": {
      "utterance": "...",
      "speaker": "A|B",
      "timestamps": ["hh:mm:ss:ff", "hh:mm:ss:ff"],
      "emotion": ["Neutral|Sad|Anger|..."]
    },
    ...
  },
  "target_change_utt_ids": [["utt_start","utt_end"], ...],
  "target_change_emos": [["from_emotion"],["to_emotion"]],
  "rationale": {
    "stimulus": { "textual": "...", "visual": null|"..." },
    "appraisal": "...",
    "response": "..."
  }
}
```

* **视频文件**：`video_path` 指定的 MP4 文件，帧率默认 25fps。

#### 2.2 输出数据

标准化后每条样本格式：

```json
{
  "id": "<sample_id>",
  "video_path": "...",
  "utterances": [
    {
      "id": "<utt_id>",
      "text": "<- utterance 字段 ->",
      "speaker": "A|B",
      "start_sec": <float>,
      "end_sec": <float>,
      "emotion": ["..."]
    },
    ...
  ],
  "key_frames": {
    "relevant_frames": ["<utt_id>_frame_1.jpg",...],
    ...
  },
  "change_intervals": [
    { "start_idx": <int>, "end_idx": <int>,
      "from_emotion": [...], "to_emotion": [...] },
    ...
  ],
  "rationale": { ... }
}
```

### 3. 类设计与模式

#### 3.1 类图概览

```
+-----------------+        +----------------------+      +----------------+
| SampleCleaner   |<>------| UtteranceParser      |      | FrameExtractor |
+-----------------+        +----------------------+      +----------------+
| +clean(sample)  |        | +parse(raw_utts)     |      | +extract(...)
+-----------------+        +----------------------+      +----------------+
        |                         |                               |
        |                         v                               v
        |                  +----------------+              +--------------+
        |                  | TimestampConverter |          | KeyFrameSelector |
        |                  +----------------+              +--------------+
        |                  | +to_seconds()  |              | +select()     |
        |                  +----------------+              +--------------+
        v
+-----------------+     uses          +-----------------
| ChangeIntervalBuilder |<--------------| EmotionMapper |
+-----------------+                   +-----------------
| +build_intervals() |                   | +map_ids()    |
+-----------------+                   +-----------------
```

#### 3.2 核心组件

* **SampleCleaner (Facade/Director)**

  * 负责协调调用各子模块，实现 `clean(raw_sample) -> CleanedSample`。
* **UtteranceParser (Factory + Strategy)**

  * 解析 `utts` 字典生成 `Utterance` 对象列表。
  * 支持不同语言/格式扩展。
* **TimestampConverter (Singleton)**

  * 提供 `hh:mm:ss:ff` 到秒级浮点数的转换。
* **FrameExtractor (Strategy)**

  * 根据时间区间调用外部工具（如 ffmpeg）截帧，抽象为 `FrameStrategy`。
* **KeyFrameSelector (Builder)**

  * 按新的关键帧采样策略从所有帧中选取关键帧。具体策略为：确定一个上下文窗口大小 N（例如 N = 3 或 5），找到情感变化发生的 utterance U_change (target_change_utt_ids 中的最后一个 utterance)，考虑 U_change 及其之前的 N - 1 个 utterance 作为相关 utterance 集合，对于集合中的每一个 utterance，根据其时间戳，在其持续时间内均匀采样（例如）2 帧，将所有采样的帧集合起来作为该样本的视觉输入。
* **ChangeIntervalBuilder**

  * 根据 `target_change_utt_ids` 和 `emotion` 映射为索引区间列表。

### 4. 流程说明

1. **SampleCleaner 读取原始数据**：`SampleCleaner.read(raw_json) → RawSample` 对象。
2. **解析话语信息**：`parser.parseUtterances` 解析 `utts` 字典生成 `List<Utterance>`。
3. **转换时间戳**：对每个 `Utterance`，使用 `converter.toSeconds` 将时间戳转换为秒级浮点数，设置 `start_sec` 和 `end_sec`。
4. **确定关键话语集合**
    - 设定上下文窗口大小 N（例如 N = 3 或 5）。
    - 找到 `target_change_utt_ids` 中的最后一个 utterance 作为 U_change。
    - 选取 U_change 及其之前的 N - 1 个 utterance 组成相关 utterance 集合。
5. **提取关键帧**
    - 对于相关 utterance 集合中的每个 utterance，根据其 `start_sec` 和 `end_sec`，调用 `frameExtractor.extractFrames(video_path, utterance_interval)` 在该 utterance 持续时间内均匀采样（例如）2 帧，将所有采样的帧缓存。
    - 调用 `keyFrameSelector.select(frames)` 从缓存的帧中选取关键帧，形成 `relevant_frames` 列表。
6. **构建情感变化区间**：`changeIntervalBuilder.build(utt_list, target_ids, emos)` 根据 `target_change_utt_ids` 和 `emotion` 映射为索引区间列表。
7. **组装并输出**：组装 `CleanedSample` 并序列化输出 JSON。

### 5. 开发与测试

* **单元测试**：单元测试覆盖率 ≥ 90%，重点测试时间戳转换、帧截取、新的关键帧采样策略以及区间构造。
* **CI/CD**：使用 GitHub Actions 自动执行 lint (ESLint/Pylint)、单测、打包。

---

以上为更新后的数据清洗模块设计与开发规范文档，可据此进行编码与落地。

项目结构如下：

```
data_cleaning/
├── utils/                # 工具模块
│   ├── time_utils.py    
│   └── video_processor.py 
├── parsers/              # 解析器模块
│   ├── __init__.py
│   ├── json_parser.py   
│   ├── utterance_parser.py 
│   └── change_parser.py 
├── strategies/           # 策略模块
│   ├── __init__.py
│   └── frame_sampler.py 
├── builder_factory/      # 构建器与工厂模块
│   ├── __init__.py
│   ├── sample_builder.py
│   └── sample_factory.py
├── pipeline/             # 清洗管道模块
│   └── data_pipeline.py
├── __init__.py
└── main.py               # 主程序入口
```

## 特征提取与存储开发说明书

### 1. 概述

本文档详细描述了多模态情感变化分析任务中，对话节点特征（文本、元信息、视觉）提取与存储流程的技术规范。包括输入数据、输出数据、开发流程、文件结构及注意事项。

---

### 2. 输入数据

1. **元数据文件** `processed_samples.json`

   * 格式：JSON 列表，每条记录包含：

     * `sample_id` (string)
     * `video_path` (string)：相对或绝对路径
     * `utterances` (list of dict)：

       * `utt_id`, `text`, `speaker`, `start_sec`, `end_sec`, `emotion`
     * `key_frames` (list of string)：仅包含引发情感变化的帧文件名
     * `emo_change`、`rationale` 等字段（仅用于上游）

2. **视频文件**

   * 存放路径与 `video_path` 对应，如 `data/MECR_CCAC2025/memoconv_convs/...`.

3. **模型权重**

   * 文本编码器：BERT/RoBERTa 预训练模型
   * 视觉编码器：CLIP‐ViT 或 Faster‑R‑CNN

---

### 3. 输出数据

在 `processed/features/` 目录下，按 `sample_id` 保存每条样本的特征文件：

```
data/feature/demo/
├── sample_001/                  # 样本ID目录
│   ├── text_feature/            # 文本特征（来自extract_text_feats.py）
│   │   ├── sample_001.pt        # BERT文本特征张量
│   │   └── id_mapping.json      # utterance ID映射表
│   └── video_feature/           # 视觉特征（来自extract_vis_feats.py）
│       ├── sample_001_video.pt  # CLIP视觉特征张量
│       └── id_mapping.json      # 与文本特征一致的ID映射
├── sample_002/
│   ├── text_feature/
│   └── video_feature/
└── ...                          # 其他样本目录
```

#### 3.1 节点特征文件 (`nodes/{sample_id}.pt`)

* **类型**：PyTorch 保存的 `dict`
* **结构**：

  * `node_feats`: `Tensor[N, D_text + D_meta + D_vis]`

    * 文本特征 `768` + 元信息 `96` + 视觉特征 `512` = `1376`
  * `vis_mask`: `Tensor[N]` (`uint8`)，1 表示对应节点有视觉特征，否则 0
  * （可选）`speaker_ids`: `Tensor[N]`, 0/1 映射
  * （可选）`emo_ids`: `Tensor[N, E]`, one‑hot 或索引

#### 3.2 FAISS 索引文件 (`faiss/*.idx`)

* `stimulus_text.idx`: 文本刺激向量索引，存储所有 `rationale.stimulus.textual` 的 BERT pooled 输出（`768` 维）
* `stimulus_vis.idx`: 视觉刺激索引，存储对应帧特征（`512` 维）
* `full_rationale.idx`: 完整解释索引，存储拼接后的 rationale 文本向量（`768` 维）

---

### 4. 特征提取流程

1. **解析元数据**

   * 加载 `processed_samples.json`，遍历每个 `sample`。
2. **文本特征提取**

   * 对 `sample["utterances"]` 中的 `text` 列表，用 BERTTokenizer 编码，BertModel 获取 `pooler_output`，得到 `t_feats` (`[N,768]`)。
3. **元信息特征构造**

   * `speaker_ids`、`emotion_ids`、`position_encoding` 构建并拼接为 `meta_feats` (`[N,96]`)。
4. **视觉特征提取**

   * 对 `key_frames` 中对应的 `utt_id`，调用视觉编码器提取每帧特征，平均得到 `v_feats[i]`；其余节点 `v_feats[i]=0`。
   * 同时生成 `vis_mask[i]=1/0`。
5. **节点特征合并**

   * `node_feats = concat(t_feats, meta_feats, v_feats)` → `[N,1376]`。
6. **保存**

   * `torch.save({"node_feats": node_feats, "vis_mask": vis_mask, ...}, "nodes/{sample_id}.pt")`
7. **FAISS 索引构建**

   * 收集所有样本的 `stimulus.textual`，BERT 编码后归一化，`IndexFlatIP` 添加并持久化为 `stimulus_text.idx`。
   * 类似流程构建 `stimulus_vis.idx`（平均帧特征）和 `full_rationale.idx`。

---

### 5. 注意事项

* 确保文本与视觉编码批量化并行，提高效率
* 对视觉特征做 L2 标准化再存储，便于相似度检索
* 版本控制 `processed_samples.json` 与 `features/` 目录，可使用 DVC
* 日志记录每个 sample 处理状态，便于重跑失败任务

---

### 6. 示例代码结构

```
src/
├── extract_text_feats.py    # 文本特征脚本
├── extract_vis_feats.py     # 视觉特征脚本
├── build_node_feats.py      # 合并并保存 nodes/*.pt
└── build_faiss.py           # 构建并保存 faiss 索引
```

---

以上即为特征提取与存储的开发规范，覆盖输入、输出、处理流程及文件结构说明。
